import os
import json
import datetime
import re
import logging
import openai
import requests
import time

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
TINYURL_API_KEY = os.getenv('TINYURL_API_KEY')

logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(message)s')

def summarize_article(title, body):
    if not OPENAI_API_KEY:
        logging.warning('OPENAI_API_KEY not set, returning first 3 lines as dummy summary.')
        lines = body.split('\n')
        return lines[:3]
    client = openai.OpenAI(api_key=OPENAI_API_KEY)
    max_length = 2000
    if len(body) > max_length:
        body = body[:max_length]
    prompt = f"""

You are very talented Daily News Report creator. Read through the biospace news then refer to the format below, and create visually neat news report.
2-3 bullet points including the specifics (whether it be clinial data, deal or etc) in Korean. Make sure the translation is very natural, without hallucination.

ê¸°ì‚¬ ë³¸ë¬¸:
{body}

Format sample:

â–· FDA (#í•­ì•”ì œì‹¬ì‚¬ #ì¸ë ¥ê°ì¶•)
â€¢ FDA, í•­ì•”ì œ ìë¬¸ìœ„(ODAC) ì¤€ë¹„ ê³¼ì •ì—ì„œ ì¸ë ¥ ê°ì¶• ì—¬íŒŒë¡œ í˜¼ë€ ë°œìƒ
â€¢ ê¸°ì¡´ ì „ë¬¸ ì¸ë ¥ ëŒ€ê±° ì´íƒˆ, ìë¬¸ìœ„ ì¤€ë¹„ì— ê²½í—˜ ë¶€ì¡± ìì›ë´‰ì‚¬ì íˆ¬ì…
â€¢ ë‚´ë¶€ ê´€ê³„ì â€œì‹¬ì‚¬ ì‹ ë¢°ì„±Â·ì „ë¬¸ì„± ì €í•˜ ìš°ë ¤â€¦ë‚´ì£¼ 3ê±´ í•­ì•”ì œ ì‹¬ì‚¬ ì¼ì • ì°¨ì§ˆ ê°€ëŠ¥ì„±â€

â–· Bluebird (#ë°”ì´ì•„ì›ƒ #ìœ ì „ìì¹˜ë£Œì œ)
â€¢ Bluebird, ì‚¬ëª¨í€ë“œì— ì¸ìˆ˜ë˜ë©° ì£¼ì£¼ì— í˜„ê¸ˆ ìœ ì… í™•ëŒ€
â€¢ ì¸ìˆ˜ ëŒ€ê°€ë¡œ ê¸°ì¡´ ì£¼ì£¼ì— ì£¼ë‹¹ $13.50 í˜„ê¸ˆ ì§€ê¸‰, ì´ ê±°ë˜ ê·œëª¨ 6ì–µ ë‹¬ëŸ¬ ì´ìƒ
â€¢ ì‹ ì•½ íŒŒì´í”„ë¼ì¸(ìœ ì „ìì¹˜ë£Œì œ) ê°œë°œ ìê¸ˆ í™•ë³´ ë° êµ¬ì¡°ì¡°ì • ëª©ì 

â–· Biohaven (#ì‹ ê²½ì§ˆí™˜ #FDAì—°ê¸°)
â€¢ FDA, Biohavenì˜ ì²™ìˆ˜ì†Œë‡Œì‹¤ì¡°ì¦(SCA) ì‹ ì•½ BHV-4157 ìŠ¹ì¸ ê²°ì • 3ê°œì›” ì—°ê¸°
â€¢ FDA â€œì¶”ê°€ ì„ìƒ ë°ì´í„° í•„ìš”â€ í†µë³´, ê¸°ì¡´ PDUFA ì¼ì •(5ì›” 20ì¼)ì—ì„œ 8ì›”ë¡œ ì—°ê¸°
â€¢ SCA í™˜ì ëŒ€ìƒ ì„ìƒ 3ìƒì—ì„œ ìš´ë™ê¸°ëŠ¥ ê°œì„  íš¨ê³¼ ì…ì¦, ì‹œì¥ ê¸°ëŒ€ê° ì—¬ì „

â–· Sanofi (#ë¯¸êµ­íˆ¬ì #ê³µì¥ì‹ ì„¤)
â€¢ Sanofi, ë¯¸êµ­ ë‚´ ìƒì‚°ì‹œì„¤ì— 200ì–µ ë‹¬ëŸ¬ ì‹ ê·œ íˆ¬ì ë°œí‘œ
â€¢ ì¸ë””ì• ë‚˜Â·ë…¸ìŠ¤ìºë¡¤ë¼ì´ë‚˜ ë“± 3ê°œ ì£¼ì— ëŒ€ê·œëª¨ ê³µì¥ ì‹ ì„¤, 2,500ëª… ì‹ ê·œ ê³ ìš©
â€¢ CEO â€œë¯¸êµ­ ë‚´ ê³µê¸‰ë§ ê°•í™”Â·ì°¨ì„¸ëŒ€ ë°±ì‹  ìƒì‚° ì—­ëŸ‰ í™•ëŒ€â€ ê°•ì¡°

â–· AbbVie (#ADC #íì•”ì‹ ì•½)
â€¢ AbbVie, í•­ì²´-ì•½ë¬¼ì ‘í•©ì²´(ADC) ì‹ ì•½ â€˜Teliso-Vâ€™ë¡œ ë¹„ì†Œì„¸í¬íì•”(NSCLC) ì ì‘ì¦ FDA ì‹ ì† ìŠ¹ì¸
â€¢ ì„ìƒ 2ìƒì—ì„œ ê°ê´€ì  ë°˜ì‘ë¥ (ORR) 35%, ë¬´ì§„í–‰ìƒì¡´ê¸°ê°„(PFS) 5.7ê°œì›” ê¸°ë¡
â€¢ ê²½ìŸì‚¬ Daiichi Sankyo, AstraZeneca ë“±ê³¼ ADC ì‹œì¥ ì£¼ë„ê¶Œ ê²½ìŸ

"""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
        max_tokens=400
    )
    summary = response.choices[0].message.content.strip()
    return summary

def shorten_url(url):
    try:
        if TINYURL_API_KEY:
            api_url = f'https://api.tinyurl.com/create'
            headers = {'Authorization': f'Bearer {TINYURL_API_KEY}', 'Content-Type': 'application/json'}
            data = {"url": url}
            resp = requests.post(api_url, headers=headers, json=data)
            if resp.ok:
                return resp.json()['data']['tiny_url']
        # fallback: public endpoint
        resp = requests.get(f'https://tinyurl.com/api-create.php?url={url}')
        if resp.ok:
            return resp.text.strip()
    except Exception as e:
        logging.warning(f'URL ë‹¨ì¶• ì‹¤íŒ¨: {e}')
    return url

def format_section_block(summary, short_url):
    lines = summary.strip().split('\n')
    hashtags = ''
    if lines and lines[-1].startswith('#'):
        hashtags = lines.pop(-1)
    if hashtags:
        if '(' in lines[0]:
            lines[0] = re.sub(r'\)$', f' {hashtags})', lines[0])
        else:
            lines[0] += f' ({hashtags})'
    lines.append(f'{short_url}')
    return '\n'.join(lines)

def make_daily_report(news_blocks):
    today = datetime.datetime.now()
    header_date = today.strftime('%Yë…„ %mì›” %dì¼')
    header = f'í•´ì™¸ ì œì•½/ë°”ì´ì˜¤ ì†Œì‹ {header_date}'
    blocks = [
        {"type": "header", "text": {"type": "plain_text", "text": header, "emoji": True}},
        {"type": "header", "text": {"type": "plain_text", "text": "ğŸ”¬ ë°”ì´ì˜¤ìŠ¤í˜ì´ìŠ¤ ë°ì¼ë¦¬ ë¦¬í¬íŠ¸", "emoji": True}},
        {"type": "divider"}
    ]
    blocks.extend(news_blocks)
    return {
        "channel": "research",
        "blocks": blocks
    }

def main():
    logging.info('clipped_news.json â†’ daily_report.json ë³€í™˜ ì‹œì‘...')
    with open('clipped_news.json', 'r', encoding='utf-8') as f:
        news_items = json.load(f)
    news_blocks = []
    for i, news in enumerate(news_items):
        title = news['title']
        url = news['url']
        body = news['body']
        if not title or not body:
            logging.warning(f'[{i+1}/5] ê¸°ì‚¬ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨, ê±´ë„ˆëœ€')
            continue
        summary = summarize_article(title, body)
        short_url = shorten_url(url)
        section_block = {
            "type": "section",
            "text": {"type": "mrkdwn", "text": format_section_block(summary, short_url)}
        }
        news_blocks.append(section_block)
        time.sleep(1) 
    while len(news_blocks) < 5:
        news_blocks.append({
            "type": "section",
            "text": {"type": "mrkdwn", "text": "(ë‰´ìŠ¤ ì—†ìŒ)"}
        })
    report = make_daily_report(news_blocks[:5])
    with open('daily_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    logging.info('daily_report.json ìƒì„± ì™„ë£Œ!')

if __name__ == '__main__':
    main() 
